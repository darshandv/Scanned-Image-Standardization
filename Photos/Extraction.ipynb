{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00045609474182128906 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "print(time.time()-start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def order_points(pts,crop,main=0):\n",
    "    ''' The function returns the 4 corner points in a set of points. \n",
    "    The input are a set of points (pts).\n",
    "    crop is the amount of pixels that are subtracted from the four points obtained which is kind of padding.\n",
    "    main is the flag which exclusively runs when the ordering points are of the main form'''\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    " \n",
    "\n",
    "    s = pts.sum(axis = 1)\n",
    "#     print(s)\n",
    "#     print(pts)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    " \n",
    "\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    \n",
    "    if main:\n",
    "        rect[1][1]-=110\n",
    "        rect[0][0] -=20\n",
    "    \n",
    "    #cropping a little more towards left\n",
    "    rect[0][0] -=crop\n",
    "    rect[3][0] -=crop\n",
    "    #cropping a little more towards right\n",
    "    rect[1][0] +=crop\n",
    "    rect[2][0] +=crop\n",
    "    #cropping a little more towards bottom\n",
    "    rect[3][1] +=crop\n",
    "    rect[2][1] +=crop\n",
    " \n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outer_points(pts,crop):\n",
    "\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    " \n",
    "    min_x = min(pts[:,0])\n",
    "    min_y = min(pts[:,1])\n",
    "    max_x = max(pts[:,0])\n",
    "    max_y = max(pts[:,1])\n",
    "    #s = pts.sum(axis = 1)\n",
    "    #print(s)\n",
    "    rect[0][0] = min_x\n",
    "    rect[0][1] = min_y\n",
    "    rect[2][0] = max_x\n",
    "    rect[2][1] = max_y\n",
    " \n",
    "\n",
    "    #diff = np.diff(pts, axis = 1)\n",
    "    #print(diff)\n",
    "    rect[1][0] = max_x\n",
    "    rect[1][1] = min_y\n",
    "    rect[3][0] = min_x\n",
    "    rect[3][1] = max_y\n",
    "    \n",
    "    #cropping a little more towards left\n",
    "    rect[0][0] -=crop\n",
    "    rect[3][0] -=crop\n",
    "    #cropping a little more towards right\n",
    "    rect[1][0] +=crop\n",
    "    rect[2][0] +=crop\n",
    "    #cropping a little more towards bottom\n",
    "    rect[3][1] +=crop\n",
    "    rect[2][1] +=crop\n",
    " \n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def four_point_warp(image, pts,crop,outer=1,main=0):\n",
    "\n",
    "    if outer:\n",
    "        rect = get_outer_points(pts,crop)\n",
    "    else :\n",
    "        rect = order_points(pts,crop,main)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    #print(rect)\n",
    "\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    dst = np.array([\n",
    "              [0, 0],\n",
    "              [maxWidth - 1, 0],\n",
    "              [maxWidth - 1, maxHeight - 1],\n",
    "              [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    cv2.imwrite('Out.jpg',warped)\n",
    " \n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_features_orb(gray_main, gray_crop, mask_tl=None, mask_br=None):\n",
    "    #Trying feature matching using ORB\n",
    "    orb = cv2.ORB_create()\n",
    "    Mask = None\n",
    "    #cv2.rectangle(mask, (int(width/10),int(18*height/25)),(int(15*width/16),int(13*height/14)), (255), thickness = -1)\n",
    "    #cv2.rectangle(mask,(int(width/10),int(2*height/17)),(int(13*width/21),int(4*height/29)),(255),-1)\n",
    "    #cv2.rectangle(mask, (int(width/10),int(18*height/25)),(int(15*width/16),int(13*height/14)), (255), thickness = -1)\n",
    "    if mask_tl and mask_br:\n",
    "        Mask = np.zeros(gray_main.shape[:2], dtype=np.uint8)\n",
    "        cv2.rectangle(Mask, mask_tl, mask_br, (255), thickness = -1)\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = orb.detectAndCompute(gray_main,mask)\n",
    "    kp2, des2 = orb.detectAndCompute(gray_crop,None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    matches = bf.match(des1,des2)\n",
    "\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "    img = cv2.drawMatches(gray_main,kp1,gray_crop,kp2,matches,None, flags=2)\n",
    "\n",
    "    #cv2.imwrite('Out1.jpg',img)\n",
    "    return np.float32([ kp1[m.queryIdx].pt for m in matches ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_features(gray_main, gray_crop, mask_tl=None, mask_br=None, Mask_main=None):\n",
    "    #Trying feature matching using SIFT\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    Mask=Mask_main\n",
    "    #mask for residential address\n",
    "    #cv2.rectangle(mask, (int(0),int(18*height/25)),(width,int(25*height/26)), (255), thickness = -1)\n",
    "    \n",
    "    if mask_tl and mask_br:\n",
    "        if Mask_main is not None:\n",
    "            cv2.rectangle(Mask, mask_tl, mask_br, (0), thickness = -1)\n",
    "        else :\n",
    "            Mask = np.zeros(gray_main.shape[:2], dtype=np.uint8)\n",
    "            cv2.rectangle(Mask, mask_tl, mask_br, (255), thickness = -1)\n",
    "    \n",
    "    #mask for branch\n",
    "    #cv2.rectangle(mask,(int(width/10),int(3*height/27)),(int(10*width/11),int(3*height/20)),(255),-1)\n",
    "    \n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(gray_main,Mask)\n",
    "    kp2, des2 = sift.detectAndCompute(gray_crop,None)\n",
    "    \n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    \n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    matches = flann.knnMatch(des1,des2,k=2,mask=Mask)\n",
    "    \n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            good.append(m)\n",
    "    \n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    \n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    \n",
    "    h,w = gray_main.shape\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    dst = cv2.perspectiveTransform(pts,M)\n",
    "    \n",
    "    \n",
    "    img2 = cv2.polylines(gray_crop,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "    \n",
    "    draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "\n",
    "    img3 = cv2.drawMatches(gray_main,kp1,gray_crop,kp2,good,None,**draw_params)\n",
    "    cv2.imwrite('Out1.jpg',img3)\n",
    "    return np.float32([ kp1[m.queryIdx].pt for m in good ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_input(main_file, crop_file):\n",
    "    img1 = cv2.imread(main_file)\n",
    "    crop = cv2.imread(crop_file)\n",
    "    gray_main = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "    gray_crop = cv2.cvtColor(crop,cv2.COLOR_BGR2GRAY)\n",
    "    height_main, width_main = gray_main.shape\n",
    "    height_crop, width_crop = gray_crop.shape\n",
    "    height = height_main\n",
    "    width = width_main\n",
    "    #print(height_main, width_main)\n",
    "    #print(height_crop, width_crop)\n",
    "    return img1, gray_main, gray_crop, height, width\n",
    "    #cv2.imwrite('Out.jpg',gray_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_selected_rectangle(img, tl, br):\n",
    "    return img[tl[1]:br[1],tl[0]:br[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled-pa.jpg\n",
      "3507 2481\n",
      "3504 2479\n",
      "[[  264.26904297   443.30407715]\n",
      " [ 2294.56762695   449.793396  ]\n",
      " [ 2271.60058594  3355.45654297]\n",
      " [  208.64698792  3335.47485352]]\n",
      "Saving into crop1\n",
      "Time taken :  88.55214929580688\n",
      "filled-s1.jpg\n",
      "3507 2481\n",
      "3504 2479\n",
      "[[  404.8944397    282.56170654]\n",
      " [ 2412.24902344   523.42895508]\n",
      " [ 2063.37841797  3405.13061523]\n",
      " [    9.07249069  3152.79516602]]\n",
      "Saving into crop2\n",
      "Time taken :  159.86106705665588\n",
      "filled-s2.jpg\n",
      "3507 2481\n",
      "3504 2479\n",
      "[[   20.54397583   396.99411011]\n",
      " [ 2054.51904297   254.73965454]\n",
      " [ 2251.46191406  3151.02172852]\n",
      " [  193.62646484  3291.29003906]]\n",
      "Saving into crop3\n",
      "Time taken :  236.05063772201538\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "types = ('*.jpg', '*.JPG','*.JPEG', '*.jpeg')\n",
    "files = []\n",
    "os.system(\"mkdir crop\")\n",
    "os.chdir(os.getcwd() + \"/form-samples/\")\n",
    "for t in types:\n",
    "    if glob.glob(t) != [] :\n",
    "        files.append(glob.glob(t))\n",
    "os.chdir(\"../crop/\")\n",
    "i=1\n",
    "for f in files[0]:\n",
    "    print(f)\n",
    "    img1, gray_main, gray_crop, height, width = read_input('../form-samples/'+f, '../form_print.jpg')\n",
    "    mask = np.zeros(gray_main.shape[:2], dtype=np.uint8)+255\n",
    "    points = compare_features(gray_main, gray_crop, (0,int(height/4)),(width,int(18*height/25)),mask)\n",
    "    crop = 30\n",
    "    dst = four_point_warp(gray_main, points, crop, outer=0, main=1)\n",
    "    height, width = dst.shape\n",
    "    \n",
    "    os.system(\"mkdir crop\"+str(i))\n",
    "    branch = crop_selected_rectangle(dst,(int(width/20),int(height/20)),(int(7*width/11),int(3*height/37)))\n",
    "    print('Saving into crop'+str(i))\n",
    "    os.chdir(os.getcwd()+'/crop'+str(i))\n",
    "    cv2.imwrite('branch.jpg',branch)\n",
    "    os.chdir('../')\n",
    "    print('Time taken : ',time.time()-start_time)\n",
    "    i=i+1\n",
    "    #print(height,width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1191.1624717712402\n",
      "2902 2062\n"
     ]
    }
   ],
   "source": [
    "crop = 30\n",
    "dst = four_point_warp(gray_main, points, crop, outer=0, main=1)\n",
    "print(time.time()-start_time)\n",
    "height, width = dst.shape\n",
    "print(height,width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crop branch\n",
    "# cv2.rectangle(dst,(int(width/20),int(height/20)),(int(7*width/11),int(3*height/37)),(0),3)\n",
    "# branch = crop_selected_rectangle(dst,(int(width/20),int(height/20)),(int(7*width/11),int(3*height/37)))\n",
    "cv2.rectangle(dst,(int(20*width/30),int(height/20)),(int(34*width/35),int(3*height/37)),(0),3)\n",
    "cv2.imwrite('Out.jpg',dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/darshan/CS/Summer2018/Impel/OCR/Darshan/Photos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "# os.system(\"mkdir crop\")\n",
    "#os.chdir('..')\n",
    "# os.system(\"mkdir crop\"+str(i))\n",
    "print(os.getcwd())\n",
    "str('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For residential address\n",
    "# address_x = (int(0),int(18*height/25))\n",
    "# address_y = (width,int(25*height/26))\n",
    "\n",
    "# points = compare_features(gray_main, gray_crop, address_x, address_y)\n",
    "# points = points[points[:,1]>(7*height)/10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
