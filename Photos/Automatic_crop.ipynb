{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5693860054016113 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "print(time.time()-start,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Just put it to another file because it was consuming space here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2\n",
    "Better approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    " \n",
    "\n",
    "    s = pts.sum(axis = 1)\n",
    "#     print(s)\n",
    "#     print(pts)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    " \n",
    "\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    " \n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    dst = np.array([\n",
    "              [0, 0],\n",
    "              [maxWidth - 1, 0],\n",
    "              [maxWidth - 1, maxHeight - 1],\n",
    "              [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    " \n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cont(img, gray, user_thresh, crop, filename):\n",
    "    found = False\n",
    "    cwd = os.getcwd() + '/crop/'\n",
    "    orig_thresh = user_thresh\n",
    "    im_h, im_w = img.shape[:2]\n",
    "    while found == False: # repeat to find the right threshold value for finding a rectangle\n",
    "        if user_thresh < 200:\n",
    "            user_thresh = orig_thresh + 5\n",
    "            orig_thresh = user_thresh \n",
    "        print(user_thresh)\n",
    "        ret,thresh = cv2.threshold(gray,user_thresh,255,cv2.THRESH_BINARY)\n",
    "        _,contours,hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "        im_area = im_w * im_h\n",
    "        for cnt in contours:         \n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > (im_area/6) and area < (im_area/1.01):\n",
    "                epsilon = 0.1*cv2.arcLength(cnt,True)\n",
    "                approx = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "                if len(approx) == 4:\n",
    "                    found = True\n",
    "                else:\n",
    "                    user_thresh = user_thresh - 1\n",
    "                    break                \n",
    "                rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "                rect[0] = approx[0]\n",
    "                rect[1] = approx[1]\n",
    "                rect[2] = approx[2]\n",
    "                rect[3] = approx[3]\n",
    "                \n",
    "                dst = four_point_transform(img, rect)\n",
    "                dst_h, dst_w = dst.shape[:2]\n",
    "                img = dst[crop:dst_h-crop, crop:dst_w-crop]\n",
    "                dst_h, dst_w = img.shape[:2]\n",
    "                #print(\"Saving to \"+cwd+\"crop_\"+filename)\n",
    "                #cv2.imwrite(cwd+\"crop_\"+filename, img, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "                #res = cv2.resize(img,(dst_w/6, dst_h/6), interpolation = cv2.INTER_CUBIC)\n",
    "          \n",
    "    return found, im_w, im_h, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(thresh, crop, filename):\n",
    "    img = cv2.imread(filename)\n",
    "    print(\"Opening: \"+filename)\n",
    "\n",
    "    #add white background (in case one side is cropped right already, otherwise script would fail finding contours)\n",
    "    #img = cv2.copyMakeBorder(img,100,100,100,100, cv2.BORDER_CONSTANT,value=[255,255,255])\n",
    "    im_h, im_w = img.shape[:2]\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    res_gray = cv2.resize(img,(int(im_w/6), int(im_h/6)), interpolation = cv2.INTER_CUBIC)\n",
    "    found, im_w, im_h, image = cont(img, gray, thresh, crop, filename)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.system(\"mkdir crop\")\n",
    "thresh = 166\n",
    "crop = 15\n",
    "files = []\n",
    "types = ('*.bmp','*.BMP','*.tiff','*.TIFF','*.tif','*.TIF','*.jpg', '*.JPG','*.JPEG', '*.jpeg', '*.png', '*.PNG', ) #all should work but only .jpg was tested\n",
    "for t in types:\n",
    "    if glob.glob(t) != []:\n",
    "        files.append(glob.glob(t))\n",
    "# for f in files[0]:\n",
    "img1 = main(thresh, crop, 'form-samples/filled-s1.jpg')\n",
    "print(img1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm-1\n",
    "If the form is standard and perfect this code will work better. Can generate both grayscale and colour images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('form-samples/filled-s1.jpg')\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3507\n",
      "2481\n",
      "(39, 1287)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height, width = gray.shape\n",
    "print(height)\n",
    "print(width)\n",
    "\n",
    "#for Residential Address\n",
    "out = cv2.rectangle(gray,(int(width/10),int(17*height/23)),(int(10*width/11),int(9*height/10)),(0,255,0),2)\n",
    "## out = cv2.rectangle(gray,(int(width/10),int(18*height/25)),(int(15*width/16),int(13*height/14)),(0,255,0),2)\n",
    "# Branch \n",
    "out = cv2.rectangle(gray,(int(width/10),int(3*height/17)),(int(13*width/21),int(6*height/32)),(0,255,0),2)\n",
    "out = cv2.rectangle(gray, (int(0),int(18*height/25)),(width,int(25*height/26)), (0), thickness = -1)\n",
    "\n",
    "\n",
    "# Residential address\n",
    "out1 = gray[int(17*height/23):int(9*height/10),int(width/10):int(10*width/11)]\n",
    "\n",
    "#Branch\n",
    "out1 = gray[int(3*height/17):int(6*height/32),int(width/10):int(13*width/21)]\n",
    "print(out1.shape)\n",
    "\n",
    "cv2.imwrite('Out.jpg',out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2\n",
    "Even if the form is skewed but has darker background the algorithm takes care of it and crops the address field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3507 2481\n",
      "285 1090\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread('form-samples/filled-s1.jpg')\n",
    "crop = cv2.imread('Residential_address.jpg')\n",
    "gray_main = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "gray_crop = cv2.cvtColor(crop,cv2.COLOR_BGR2GRAY)\n",
    "height_main, width_main = gray_main.shape\n",
    "height_crop, width_crop = gray_crop.shape\n",
    "height = height_main\n",
    "width = width_main\n",
    "print(height_main, width_main)\n",
    "print(height_crop, width_crop)\n",
    "#cv2.imwrite('Out.jpg',gray_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Trying feature matching using ORB\n",
    "orb = cv2.ORB_create()\n",
    "mask = np.zeros(gray_main.shape[:2], dtype=np.uint8)\n",
    "#cv2.rectangle(mask, (int(width/10),int(18*height/25)),(int(15*width/16),int(13*height/14)), (255), thickness = -1)\n",
    "#cv2.rectangle(mask,(int(width/10),int(2*height/17)),(int(13*width/21),int(4*height/29)),(255),-1)\n",
    "cv2.rectangle(mask, (int(width/10),int(18*height/25)),(int(15*width/16),int(13*height/14)), (255), thickness = -1)\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = orb.detectAndCompute(gray_main,mask)\n",
    "kp2, des2 = orb.detectAndCompute(gray_crop,None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "matches = bf.match(des1,des2)\n",
    "\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "img = cv2.drawMatches(gray_main,kp1,gray_crop,kp2,matches,None, flags=2)\n",
    "\n",
    "cv2.imwrite('Out1.jpg',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Trying feature matching using SIFT\n",
    "# Initiate SIFT detector\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "mask = np.zeros(gray_main.shape[:2], dtype=np.uint8)\n",
    "#mask for residential address\n",
    "cv2.rectangle(mask, (int(0),int(18*height/25)),(width,int(25*height/26)), (255), thickness = -1)\n",
    "\n",
    "#mask for branch\n",
    "#cv2.rectangle(mask,(int(width/10),int(3*height/27)),(int(10*width/11),int(3*height/20)),(255),-1)\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(gray_main,mask)\n",
    "kp2, des2 = sift.detectAndCompute(gray_crop,None)\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "matches = flann.knnMatch(des1,des2,k=2,mask=mask)\n",
    "\n",
    "# store all the good matches as per Lowe's ratio test.\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.8*n.distance:\n",
    "        good.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "matchesMask = mask.ravel().tolist()\n",
    "\n",
    "h,w = gray_main.shape\n",
    "pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "\n",
    "img2 = cv2.polylines(gray_crop,[np.int32(dst)],True,255,3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "\n",
    "img3 = cv2.drawMatches(gray_main,kp1,gray_crop,kp2,good,None,**draw_params)\n",
    "cv2.imwrite('Out1.jpg',img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For approach 1\n",
    "# src_pts = np.float32([ kp1[m.queryIdx].pt for m in matches ])\n",
    "# point = src_pts\n",
    "\n",
    "\n",
    "# #For approach 2\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ])\n",
    "point = src_pts\n",
    "\n",
    "# #for Residential address\n",
    "point = src_pts\n",
    "points = point[point[:,1]>(7*height)/10]\n",
    "\n",
    "#for Branch name\n",
    "# point = src_pts\n",
    "# points = point[point[:,1]<(height)/8]\n",
    "\n",
    "#for Name\n",
    "# point = src_pts\n",
    "# points = point[point[:,1]>(height)/8]\n",
    "# points = points[points[:,1]<2*(height)/8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outer_points(pts,crop):\n",
    "\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    " \n",
    "    min_x = min(pts[:,0])\n",
    "    min_y = min(pts[:,1])\n",
    "    max_x = max(pts[:,0])\n",
    "    max_y = max(pts[:,1])\n",
    "    #s = pts.sum(axis = 1)\n",
    "    #print(s)\n",
    "    rect[0][0] = min_x\n",
    "    rect[0][1] = min_y\n",
    "    rect[2][0] = max_x\n",
    "    rect[2][1] = max_y\n",
    " \n",
    "\n",
    "    #diff = np.diff(pts, axis = 1)\n",
    "    #print(diff)\n",
    "    rect[1][0] = max_x\n",
    "    rect[1][1] = min_y\n",
    "    rect[3][0] = min_x\n",
    "    rect[3][1] = max_y\n",
    "    \n",
    "    #cropping a little more towards left\n",
    "    rect[0][0] -=crop\n",
    "    rect[3][0] -=crop\n",
    "    #cropping a little more towards right\n",
    "    rect[1][0] +=crop\n",
    "    rect[2][0] +=crop\n",
    "    #cropping a little more towards bottom\n",
    "    rect[3][1] +=crop\n",
    "    rect[2][1] +=crop\n",
    " \n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def four_point_warp(image, pts,crop):\n",
    "\n",
    "    rect = get_outer_points(pts,crop)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    print(rect)\n",
    "\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    dst = np.array([\n",
    "              [0, 0],\n",
    "              [maxWidth - 1, 0],\n",
    "              [maxWidth - 1, maxHeight - 1],\n",
    "              [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    cv2.imwrite('Out.jpg',warped)\n",
    " \n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  241.08084106  2525.06274414]\n",
      " [ 2126.73852539  2525.06274414]\n",
      " [ 2126.73852539  3254.41186523]\n",
      " [  241.08084106  3254.41186523]]\n"
     ]
    }
   ],
   "source": [
    "crop = 10\n",
    "dst = four_point_warp(gray_main, points,crop)\n",
    "dst_h, dst_w = dst.shape[:2]\n",
    "img = dst[crop:dst_h-crop, crop:dst_w-crop]\n",
    "dst_h, dst_w = img.shape[:2]\n",
    "#cv2.imwrite('Out1.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2659.2945823669434"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 2065)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
